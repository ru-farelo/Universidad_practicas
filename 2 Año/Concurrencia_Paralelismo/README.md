# Concurrencia y Paralelismo - Sistemas Distribuidos en C

## üìã Descripci√≥n del Proyecto

Conjunto de implementaciones avanzadas en **programaci√≥n concurrente y paralela** utilizando C/C++ y tecnolog√≠as como **pthreads** y **MPI**. El proyecto abarca desde sincronizaci√≥n b√°sica con mutex hasta sistemas distribuidos complejos, demostrando competencias en programaci√≥n de sistemas de alto rendimiento.

## üöÄ Caracter√≠sticas Principales

- **Programaci√≥n multihilo**: Implementaciones con pthreads y sincronizaci√≥n avanzada
- **Sistemas distribuidos**: Comunicaci√≥n inter-procesos con MPI (Message Passing Interface)
- **Estructuras de datos concurrentes**: Colas thread-safe y buffers circulares
- **Algoritmos paralelos**: Procesamiento distribuido de datos masivos
- **An√°lisis de rendimiento**: Benchmarking y optimizaci√≥n de algoritmos concurrentes
- **Gesti√≥n de memoria**: Manejo eficiente de recursos en entornos multihilo
- **Sincronizaci√≥n robusta**: Mutex, sem√°foros y variables de condici√≥n

## üèóÔ∏è Arquitectura del Proyecto

### Pr√°ctica 1 - Concurrencia con Pthreads
- **`arrayEj1.c`**: Acceso concurrente a arrays con mutex b√°sicos
- **`arrayEj2.c`**: Optimizaciones de sincronizaci√≥n y granularidad de locks
- **`arrayEj3.c`**: Algoritmos avanzados de sincronizaci√≥n
- **`arrayEj4.c`**: Patrones de concurrencia complejos
- **`options.h/c`**: Framework de configuraci√≥n y parsing de argumentos

### Pr√°ctica 2 - Sistemas Distribuidos y Hash MD5
- **`md5.c`**: Calculadora distribuida de hash MD5 con pool de threads
- **`queue.h/c`**: Implementaci√≥n de cola thread-safe con productores/consumidores
- **Arquitectura productor-consumidor**: Pipeline de procesamiento de archivos
- **Gesti√≥n de directorios**: Exploraci√≥n concurrente del sistema de archivos

### Pr√°ctica 3 - Paralelismo con MPI
- **`ejercicio1.c`**: Algoritmos distribuidos con comunicaci√≥n punto a punto
- **`ejercicio21.c`**: Operaciones colectivas y reducci√≥n paralela
- **`ejercicio22.c`**: Patrones avanzados de comunicaci√≥n MPI
- **`cuentaletras.c`**: Procesamiento paralelo de cadenas bioinform√°ticas

## üõ†Ô∏è Stack Tecnol√≥gico

- **Lenguajes**: C/C++ (est√°ndares C11/C++17)
- **Concurrencia**: POSIX Threads (pthreads), Mutex, Sem√°foros
- **Paralelismo**: MPI (Message Passing Interface), OpenMP
- **Herramientas**: GCC, Make, CMake, Valgrind
- **Bibliotecas**: OpenSSL (para MD5), LibC est√°ndar
- **Sistemas**: Linux/Unix, sistemas multiprocesador
- **Debugging**: GDB, ThreadSanitizer, Helgrind

## ‚öôÔ∏è Configuraci√≥n y Ejecuci√≥n

### Requisitos Previos

- GCC 9.0+ con soporte POSIX
- OpenMPI o MPICH
- OpenSSL development libraries
- CMake 3.16+

### Compilaci√≥n y Ejecuci√≥n

```bash
# Pr√°ctica 1 - Concurrencia
cd p1-ruben-fernandez-farelo-roi-cabana-main/
make all
./arrayEj1 -t 4 -i 1000 -d 100

# Pr√°ctica 2 - Hash MD5 distribuido
cd p2-ruben-fernandez-farelo-roi-cabana-main/
make
./md5 -d /path/to/directory -t 8

# Pr√°ctica 3 - MPI Paralelismo
cd paralelismo-cp-main/
cmake .
make
mpirun -np 4 ./ejercicio1 1000000 A
```

## üîß Implementaciones Destacadas

### Sincronizaci√≥n Avanzada con Pthreads
- **Mutex granular**: Optimizaci√≥n de locks por secciones cr√≠ticas
- **Pool de threads**: Gesti√≥n eficiente de recursos de hilos
- **Patrones producer-consumer**: Implementaci√≥n robusta con colas thread-safe
- **An√°lisis de race conditions**: Detecci√≥n y prevenci√≥n de condiciones de carrera

### Sistema de Hash MD5 Distribuido
- **Pipeline multietapa**: Arquitectura de procesamiento en flujo
- **Cola thread-safe**: Estructura de datos concurrente con sincronizaci√≥n
- **Exploraci√≥n paralela**: Recorrido concurrente de directorios
- **Agregaci√≥n de resultados**: Consolidaci√≥n thread-safe de hashes

### Algoritmos Paralelos con MPI
- **Distribuci√≥n de datos**: Particionamiento eficiente para procesamiento paralelo
- **Comunicaci√≥n colectiva**: Uso de reduce, broadcast y gather
- **Balanceamiento de carga**: Distribuci√≥n √≥ptima de trabajo entre procesos
- **An√°lisis bioinform√°tico**: Conteo paralelo de nucle√≥tidos en secuencias ADN

### Estructuras de Datos Concurrentes
- **Cola circular thread-safe**: Implementaci√≥n con mutex y variables de condici√≥n
- **Buffer compartido**: Gesti√≥n de memoria para productores m√∫ltiples
- **Gesti√≥n de estados**: Control de flujo y se√±alizaci√≥n entre threads

## üìà Competencias T√©cnicas Demostradas

- **Programaci√≥n de sistemas**: Desarrollo en C/C++ para sistemas de alto rendimiento
- **Concurrencia avanzada**: Dise√±o e implementaci√≥n de algoritmos thread-safe
- **Sistemas distribuidos**: Arquitecturas paralelas con MPI y comunicaci√≥n inter-proceso
- **Optimizaci√≥n de rendimiento**: An√°lisis y mejora de algoritmos concurrentes
- **Debugging concurrente**: Detecci√≥n de deadlocks, race conditions y memory leaks
- **Arquitectura de software**: Dise√±o de sistemas escalables y robustos
- **Matem√°ticas aplicadas**: An√°lisis de complejidad paralela y teor√≠a de colas

## üéØ Algoritmos y Patrones Implementados

### Patrones de Concurrencia
- **Producer-Consumer**: Pipeline de procesamiento con m√∫ltiples etapas
- **Reader-Writer**: Acceso concurrente con prioridad de lectores
- **Worker Pool**: Gesti√≥n eficiente de threads trabajadores
- **Fork-Join**: Paralelizaci√≥n con divisi√≥n y conquista

### T√©cnicas de Sincronizaci√≥n
- **Mutex exclusivos**: Protecci√≥n de secciones cr√≠ticas
- **Variables de condici√≥n**: Sincronizaci√≥n basada en eventos
- **Sem√°foros**: Control de acceso a recursos limitados
- **Barreras de sincronizaci√≥n**: Coordinaci√≥n de fases paralelas

### Algoritmos Distribuidos
- **Map-Reduce**: Procesamiento distribuido de grandes vol√∫menes
- **Scatter-Gather**: Distribuci√≥n y recolecci√≥n de datos
- **Pipeline paralelo**: Procesamiento en cadena optimizado
- **Load Balancing**: Distribuci√≥n din√°mica de carga de trabajo

## üî¨ An√°lisis de Rendimiento

### M√©tricas Implementadas
- **Speedup**: An√°lisis de aceleraci√≥n con m√∫ltiples cores
- **Eficiencia paralela**: Utilizaci√≥n √≥ptima de recursos computacionales
- **Escalabilidad**: Comportamiento con incremento de threads/procesos
- **Latencia vs Throughput**: Optimizaci√≥n de diferentes m√©tricas de rendimiento

### Optimizaciones Aplicadas
- **Cache efficiency**: Localidad de datos y false sharing prevention
- **Memory management**: Reducci√≥n de fragmentaci√≥n y overhead
- **Context switching**: Minimizaci√≥n de cambios de contexto
- **NUMA awareness**: Optimizaci√≥n para arquitecturas multi-socket

---

## üèõÔ∏è Contexto Acad√©mico

**Universidad de A Coru√±a (UDC)** | Facultad de Inform√°tica | Concurrencia y Paralelismo (2021-2022)

*Proyecto desarrollado aplicando t√©cnicas avanzadas de programaci√≥n paralela y sistemas distribuidos de alto rendimiento.*
